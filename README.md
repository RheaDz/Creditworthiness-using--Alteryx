# Creditworthiness-using-Alteryx

The project involved developing a binary classification predictive model from 4 different algorithms to determine if a customer is creditworthy or non-creditworthy.
It required hyperparameter tuning of the models to get the optimal model for each algorithm and resampling to select the model that has the best performance for our prediction.

### How Do I Complete this Project?
This project uses skills learned throughout the "Classification Models" course. To complete this project:

Go through the course
Apply the skills learned in the course to solve the business problem given in the project details section.
Use our guidelines and rubric to help build your project.
When you're ready, submit it to us for review using the submission template found in the supporting materials section.

### Skills Required
In order to complete this project, you must be able to:

Cleanup, format, and blend a wide range of data sources
Build predictive classification models using Logistic Regression, Decision Tree, Random Forest, and Boosted Model

### Explanation
The project involved developing a binary classification predictive model from 4 different algorithms to determine if a customer is creditworthy or non-creditworthy. 
It required hyperparameter tuning of the models to get the optimal model for each algorithm and resampling to select the model that has the best performance for our prediction.
Performed Cleanup, format, and blend a wide range of data sources Build predictive classification models using Logistic Regression, Decision Tree, Random Forest, and Boosted Model

Converted categorical data into numerical values and simplified categories to create meaningful and informative features that can improve the performance of machine learning models. By combining categories we simplify the model's decision-making process and reducing the dimensionality of the data.

Performing Oversampling to correct the imbalance so that the train model is not biased.
Build predictive classification models using **Logistic Regression Model/Decision Tree/Random Forest/Boosted Model**

### Key Insights:

1. Linear Regression: The interactive report displays various metrics related to model training, including accuracy, precision, recall, F1 score, and a confusion matrix. It suggests that the model has performed 
   reasonably well
2. Decision Trees and Random Forests. Both models achieved a similar level of accuracy, and variable importance was assessed in the Random Forest model.
3. The static report for the Boosted model is examined. It reveals that 4,000 trees were used by this gradient boosting model.
4. The variable importance plot highlights the most important predictor variables. In this case, "account balance," "duration of credit," and "purpose" are identified as the most important.

However, The Logistic Regression model performed the best on the training data, but the Decision Tree and Random Forest models also showed good performance.
The Random Forest model performs equally well in predicting creditworthy and non-creditworthy customers.


